{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "\n",
    "In the modern era, Artificial Intelligence (AI) has become an integral part of our daily lives, revolutionizing industries and redefining the way we interact with technology. From self-driving cars to personalized medicine, the applications of AI are vast and transformative. However, with this rapid expansion comes a set of unique challenges that must be addressed to ensure the safe and effective deployment of AI systems.\n",
    "\n",
    "**Security** is paramount. As AI models become integral to critical systems, they become targets. Malicious actors are increasingly exploring ways to deceive and manipulate AI models through adversarial inputs. Such vulnerabilities can have dire consequences, especially in high-stakes applications like autonomous driving or medical diagnostics.\n",
    "\n",
    "**Bias** in AI is another pressing concern. Models trained on biased data can perpetuate or even exacerbate existing prejudices, leading to unfair or discriminatory outcomes. In content generation, for instance, unintended biases can manifest in outputs that are misleading or offensive.\n",
    "\n",
    "When it comes to **Large Language Models (LLMs)**, two additional challenges arise:\n",
    "\n",
    "- **Alignment**: It's crucial that these models not only generate coherent responses but also truly understand and adhere to user intent. Misalignment can lead to outputs that, while grammatically correct, might be contextually inappropriate or misleading.\n",
    "\n",
    "- **Safety**: Given the vast knowledge and generative capabilities of LLMs, there's a risk of producing outputs that could be harmful, misleading, or inappropriate. Ensuring the safety of these outputs is of utmost importance.\n",
    "\n",
    "To address these challenges, especially those related to security, tools like the **Adversarial Robustness Toolbox (ART)** have emerged as invaluable assets. Throughout this tutorial, we will use the ART library, a leading Python library dedicated to adversarial machine learning. It provides a rich set of functionalities to craft adversarial attacks, implement defenses, and evaluate the robustness of AI models.\n",
    "\n",
    "# Table of Contents\n",
    "* Background: AI Models and Adversarial Threats\n",
    "    1. Evasion Attacks\n",
    "    2. Poisoning Attacks\n",
    "    3. Extraction Attacks\n",
    "    4. Inference Attacks\n",
    "* Crafting Adversarial Examples\n",
    "* Defending Against Attacks\n",
    "    1. Defence Against Evasion Attacks\n",
    "    2. Defence Against Poisoning Attacks\n",
    "    3. Defence Against Extraction Attacks\n",
    "    4. Defence Against Inference Attacks\n",
    "* Conclusion and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Background: AI Models and Threats**\n",
    "\n",
    "\n",
    "Artificial Intelligence (AI) systems are mathematical constructs trained to perform specific tasks by learning patterns from data. The most prevalent form of AI-systems today is machine learning (ML), where models are trained to make predictions or decisions based on input data. Deep learning is a subset of ML that uses neural networks to model complex patterns in large datasets. These models have been particularly successful in tasks like image processing, speech recognition, and natural language processing (NLP).\n",
    "\n",
    "However, these models are not infallible. Their reliance on data and the patterns they learn make them susceptible to various threats, especially when malicious actors aim to deceive or exploit them.\n",
    "\n",
    "<center><img src=\"imgs/adversarial_threats_attacker.PNG\" width=\"600\" height=\"400\"/></center>\n",
    "\n",
    "\n",
    "Understanding potential threats against AI-systems is crucial. Here, we introduce the most relevant attacks on AI-systems:\n",
    "\n",
    "\n",
    "\n",
    "### 1. **Evasion Attacks**:\n",
    "   In these attacks, attackers tweak the input data to deceive a trained model and cause a misclassification. This tweaked input is called an adversarial example. Evasion attacks can be separated into targeted attacks, where the attacker forces the model to predict a desired target value, and untargeted attacks that cause a general reduction in model accuracy or prediction confidence. These attacks can take place in both the physical and digital worlds.\n",
    "\n",
    "   One of the most famous examples is an image of a panda. By adding a small, almost imperceptible noise to the image, a deep learning model misclassifies it as a \"gibbon\" instead of a \"panda\", even though to human eyes, the image still clearly looks like a panda.\n",
    "\n",
    "   <center><img src=\"imgs/adversarial_example.PNG\" width=\"800\" height=\"300\"/></center>\n",
    "   \n",
    "   *_[Image Source](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm)_*.\n",
    "\n",
    "   - **Physical World Application**: Evasion attacks are not limited to the digital space. For instance, psychedelic garments can be used to trick facial recognition software into misidentifying a person. By wearing clothes with specific patterns and colors, one can be misclassified as an animal, like a zebra or giraffe, effectively evading detection.\n",
    "\n",
    "   <center><img src=\"imgs/trick_ai_system.PNG\" width=\"800\" height=\"300\"/></center>\n",
    "\n",
    "   *_[Image Source](https://www.thisiscolossal.com/2023/02/capable-facial-recognition-textiles/)_*.\n",
    "   \n",
    "\n",
    "\n",
    "### 2. **Poisoning Attacks**:\n",
    "   In poisoning attacks, adversaries introduce malicious or incorrect data points into the AI system's training set during the training phase. This manipulation affects the model's behavior, leading to incorrect predictions or classifications during the inference phase. \n",
    "\n",
    "   - **Types of Poisoning Attacks**:\n",
    "        - **Accuracy Drop Attack**: This attack involves adding malicious samples to the training data to reduce the model’s performance during testing.\n",
    "        \n",
    "        - **Target Misclassification Attack**: The goal here is to manipulate the model so that specific test samples are incorrectly classified during testing.\n",
    "        \n",
    "        - **Backdoor Attack**: Attackers insert a trigger in the input that causes a predetermined response from the model, while the system performs normally when the trigger is absent. For example, [researchers](https://arxiv.org/pdf/1708.06733v1.pdf) trained an image recognition AI to misinterpret a Stop road sign as a speed limit indicator when objects like a Post-it, a bomb sticker, or a flower sticker were placed on the Stop sign. \n",
    "\n",
    "      <center><img src=\"imgs/AI-backdoor-sign.PNG\" width=\"800\" height=\"250\"/></center>\n",
    "\n",
    "       *_[Image Source](https://arxiv.org/pdf/1708.06733v1.pdf)_*.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Extraction Attacks**:\n",
    "   The primary goal of extraction attacks is to steal or replicate the architecture, parameters, or knowledge embedded in a machine learning model. Attackers aim to create a similar model without authorization.\n",
    "   \n",
    "   **How they do it**: Attackers query the target model multiple times and use the outputs to understand the model's behavior, structure, or parameters. They may try to reverse-engineer the model or train a functionally equivalent model using the obtained results.\n",
    "   These attacks often target machine learning models deployed as a service, where users can input data and receive predictions without having direct access to the model's parameters or architecture.\n",
    "\n",
    "   **Example**: An attacker sends a variety of inputs to a machine learning model and collects the corresponding outputs. They then use this data to train a replica of the target model.\n",
    "\n",
    "### 4. **Inference Attacks**:\n",
    "\n",
    "These attacks try to figure out information about the data used to train the model. They're not about copying the model but learning secrets about the data it was trained on.\n",
    "\n",
    "**How they do it**:Attackers analyze the model’s predictions to gain insights into the data it was trained on. They might use this to uncover sensitive or private information about individual data points or overall data distributions.\n",
    "\n",
    "**Example**: An attacker queries a machine learning model trained on medical data and, by analyzing the outputs, is able to infer whether specific individuals’ data were included in the training set, or deduce sensitive attributes like a particular medical condition.\n",
    "\n",
    "\n",
    "> - **Extraction Attacks**: Focus on stealing the model's architecture, parameters, or embedded knowledge to replicate the model.\n",
    "> - **Inference Attacks**: Focus on uncovering sensitive information about the model’s training data, leading to potential privacy violations.\n",
    "\n",
    "\n",
    "Understanding these threats is the first step in the journey of AI robustness and security. As we delve deeper into this tutorial, we'll explore how these attacks are crafted. Specifically, we will go through a hands-on example of a popular approach to creating adversarial examples, namely the Fast Gradient Sign Method (FGSM). This method showcases how seemingly minor perturbations to input data can lead to significant misclassifications by AI models. Using the Adversarial Robustness Toolbox (ART), we'll demonstrate the practical implementation of FGSM and how models can be defended against such attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crafting Adversarial Examples:\n",
    "In this section, we will demonstrate a simple example of using [ART](https://github.com/Trusted-AI/adversarial-robustness-toolbox).  ART provides tools that enable developers and researchers to defend and evaluate Machine Learning models against the adversarial threats of Evasion, Poisoning, Extraction, and Inference. \n",
    "\n",
    "For the scope of this article, we will focus on an evasion attack, showcasing how adversarial examples can be crafted to mislead a trained model during the inference phase. In subsequent articles, we will explore other types of threats, delving into poisoning, extraction, and inference attacks, and demonstrating how to mitigate these risks.\n",
    "\n",
    "The example here trains a convolutional neural network on the MNIST dataset and creates adversarial examples using the Fast Gradient Sign Method. We use the ART classifier to train the model. Let's import the necessary libraries and set a seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "torch.manual_seed(42)\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're loading the MNIST dataset and preparing it for PyTorch processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (60000, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the MNIST dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "\n",
    "# Step 1a: Swap axes to PyTorch's NCHW format (batch size, channels, height, width)\n",
    "\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "\n",
    "x_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a subset of images from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAD7CAYAAAAbxo/tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVm0lEQVR4nO3deWwV1fvH8SlFoEBlaRAsq4iyKIvIZgkgS7GCEIUiSHBBWcJmRCJ1Y0cEFAGNIKlQkU1QWggoSMBSSkpZAwgaBdkqZalKW4oWivT3z/nNd54jvb1zO3cr79df55NzO/d87Xx5MvP0zIQUFhYWGgAAwCjj7wUAABAoKIoAACgURQAAFIoiAAAKRREAAIWiCACAQlEEAEChKAIAoFAUAQBQyrr7wZCQEG+uAw64kx5OxPkY+DgfEWjcOSe5UgQAQKEoAgCgUBQBAFAoigAAKBRFAAAUiiIAAIrbWzIABIcuXbqIHBUVJfL777/vy+UAQYUrRQAAFIoiAAAKRREAAIWeopvq1Kljjhs3bizmkpKSRK5cubLI1kdApaWlibmOHTs6tUTcQUJDQ83xnDlzxNzo0aNFnj9/vk/WBJQGXCkCAKBQFAEAUCiKAAAo9BSLEBcXJ3Lnzp3NcUxMjMuf1V9PYs23bt1yYHW403388cfmeNSoUWJu6dKlIk+aNMkna0Lp8vjjj7vM+n5Yq5SUFLe/Z+rUqTZW5X1cKQIAoFAUAQBQKIoAACghhXoDrKgPWvbaBYty5cqJXLbs/1qoPXv2FHMTJ04U+ZFHHnF5LE/l5OSIPGHCBJETEhI8Prabv8pSIRjPRzuqVasm8rx580QeMGCAOdZ7MgsXLhT55s2bzi7OTZyPwUXvGSYnJ/vke335386dc5IrRQAAFIoiAABKqdqSERkZKXJ8fLzIxW2l8IXjx4+LXJLbpSg96tWrJ3JiYqLI+u37vn37mmNf3eZC6VLS26XTpk1z+7P69g39uwMJV4oAACgURQAAFIoiAABKUPcU33jjDZGtj2IzjMDoIeo+++wzfy8BAeLpp582x4sXLxZzWVlZIuvncmZmptfWhTuD3R5iSbZO6NuG6CkCABAEKIoAACgURQAAlIDrKer3ratXry7y6NGjzbH+aLaKFSt6b2EWV69eFbl3794u562OHTvmlTUh8ISHh4s8a9YskV955RVzvGPHDjFnfYybYRhGfn6+w6vDncjVa5p27twpcteuXb22Djt7HH2NK0UAABSKIgAACkURAAAl4HqKYWFhIl++fNkv69i0aZPI1p7OggULxFx6erovloQAV7NmTZHXrVsncrt27USeO3euOZ4yZYr3FgYors6zlJQUr32v3st01dv0N64UAQBQKIoAACgBd/vUV9LS0kReuXKly3zt2jWvrwnBx/rKp6SkJDFXtWpVkTt27CjyoUOHvLYuwDAC5zalvg7rbVz9tVLe3AriDq4UAQBQKIoAACgURQAAFL/0FCtUqGCO33zzTTE3ePBgx77nypUrIp8+fdocx8bGirlLly55/D21a9cWWe8/Zmdne3xsBJZGjRqJ/P3335vju+66S8zpr8c5deqU19blSps2bUQeMWKEOdbPzUmTJol8/fp1r60L3qc/us1XW39c9RB1gfbIN64UAQBQKIoAACgURQAAFL/0FK37tfQeRkmcOXNGZOureQzDMPbv32+O9Z5iSXzyySci7969W+S1a9eaY/2xdVu2bHFsHXDe3XffLfKyZctEzsrKMseDBg0Sc/r56C364+Xi4uJEHjt2rMgFBQXmWO+DtmjRQuSYmBgnlgg/0XuKruj7BYtj7Znr/fPiepfWPqKdNfoCV4oAACgURQAAFIoiAABKSGFhYaFbHwwJcexLu3fvbo63bdvm8XHy8vJE7tOnj8gNGzYUuVevXua4f//+Hn9vSVh7UIZhGGPGjBF5/fr1Hh/bzV9lqeDk+WjVqlUrkfXXP/32228ijxs3zhyfPHnSK2syDMMIDw8XuXPnzuZ4xowZYk7fSzls2DCR9+7da47r1q0r5vQet/69dnA+Bh5r7y85OdnlZ/Ven943tPOz/n6e6f9z55zkShEAAIWiCACA4pfbp9ZbiNWrV/f4OLdu3RL5woULIuuv7qlUqZLH3+UtV69eFdl6i9cw/vuKK1e4XeUZ62P6Dh48KOZOnDghcnR0tMj5+fmOrcNKv205ffp0kUePHm2OP//8czH30Ucfiazf8rWqUqWKyPqj6CIiIopfbBE4HwNbSX8/1lukgXJ7tDjcPgUAwAaKIgAACkURAADFL495s/YpSnJfu0wZWdP1VzgFA713VL58eT+t5M4RFhYm8qpVq8xxRkaGmOvRo4fI3nqVkr4mvU/Yvn17ka2PlEtKSrL1XTVq1DDH6enpYm779u22joXgVZItF4ZhGCkpKc4tJoBwpQgAgEJRBABAoSgCAKD4pacI+JP1EWmGIft1bdu2FXPe6iHq9Nc9tWnTRmTroxENw/Xew3vuuUfkCRMmiGx97NvZs2eLnEPwc/VKJ7s9RJ31WHp/MtBeB2UHV4oAACgURQAAFIoiAACKX559an1mqS+fj3jjxg1z/NNPP4m5uXPnirxr1y6RmzRpYo4nT54s5vQelR2XLl0SuW/fviIfOHDA7WPxrEn36K94svbV9N6dN1nPm82bN4u51q1bi6yvuWbNmuZYf17u1KlTRa5QoYLI1l5QQkKCmHOyh8r56H/666Fc9RGLe35pca+aspo2bZrI+jnpLzz7FAAAGyiKAAAofrl9an2bef/+/R07bnGys7PN8cyZM11+1vooLMP475/MO+W9994TWb81awe3q9yj/3fq16+fObb7yLSS2L9/vznWH682Z84ckcePH19krly5spjTjzV27FiRf/31V/uL9QDno+/ZuV1qd80l2d6hb9Hw16umuH0KAIANFEUAABSKIgAAil96itY/e9+2bZtjxw0G+lYQvadakn4PPRz3WLcEGYZhdOjQwRzv27fP4+PqrNsmDOO/WyOsPUV9K8S5c+dEfuyxx0TOy8szx/Pnzxdz+vaia9euubliZ3E+el9xPURv9vKs32XtL95uHTrrlg1fbtegpwgAgA0URQAAFIoiAACKX14dlZOTY47Pnz8v5mrXru3r5TguMzNT5CFDhpjjPXv2iDnro+fgH4sWLTLHK1asEHPp6eluH0d/NNvs2bNFDg8PL/Jnb968KbLeK1q+fLnIW7ZsMccZGRlurxGlS3G9u5SUFK99t7VfqfcUgxlXigAAKBRFAAAUiiIAAIpf9ilaRUdHi7x06VKRg6HHOG/ePJF/+OEHkbdu3eqTdbAvzD2xsbEiW3u+3mR99q5hGMbu3bvN8caNG8VcVlaWL5bkVZyPztP39BXXy9Nf4eTqWHp/srh+pZ0+Is8+BQAgCFEUAQBQ/H77VBcVFSVyamqqT75Xp/+Z+9ChQ4v8rPU2mGEYRkFBgVfWVBxuVyGQcD56n51XRfmTfrtUv53qK9w+BQDABooiAAAKRREAACXgeorwHD0cBBLOR9/Tt1l06dJF5JL0HF1t79B7hP7qGRaHniIAADZQFAEAUCiKAAAo9BRLEXo4CCScjwg09BQBALCBoggAgEJRBABAoSgCAKBQFAEAUCiKAAAoFEUAABSKIgAACkURAACFoggAgEJRBABAoSgCAKBQFAEAUCiKAAAobr86CgCA0o4rRQAAFIoiAAAKRREAAIWiCACAQlEEAEChKAIAoFAUAQBQKIoAACgURQAAFIoiAAAKRREAAIWiCACAQlEEAEChKAIAoFAUAQBQKIoAACgURQAAFIoiAAAKRREAAIWiCACAUtbdD4aEhHhzHXBIYWGhv5fgE5yPwYHzEYHEnfORK0UAABSKIgAACkURAACFoggAgEJRBABAoSgCAKBQFAEAUCiKAAAoFEUAABSKIgAACkURAACFoggAgEJRBABAoSgCAKC4/eqo0iAiIkLk6dOni9y8eXORly1bZo4TExPFXG5ursOrAwD4G1eKAAAoFEUAABSKIgAASkhhYWGhWx8MCfH2WhzXpEkTkTdv3ixyw4YN3T5WfHy8yCNHjvR8YV7k5q8z6AXj+WjXlClTRJ44caI5DgsLc/mzhw8fFjk2NtYcZ2dni7m//vrLswW6gfPRvnLlyom8ZMkSc/ziiy+KuQ0bNog8dOhQkXNychxbV2ngzvnIlSIAAApFEQAApdTdPg0NDTXHBw4cEHMtW7YU+Y8//hBZv61Utuz/dqzUq1dPzO3YsUPk/v37i5yXl+fegh3G7arS48EHHxQ5ISHBHLdv397j465evVrk5cuXi3zo0CGRr1y54vF3cT7aV61aNZH1f6dcadeuncgHDx50ZE3eNGrUKJEjIyNFnjFjhsg3btzw+Lu4fQoAgA0URQAAFIoiAABKqespWv+cOT8/3+Vn+/TpI/K3334rcoMGDczxqVOnXB5rwIABIq9fv97l572FHk7wqF+/vsjR0dEiDxw4UOSuXbt6fU23W0dycrLHx+J8tK8kPUW9H9y2bVtH1uS0e++91xyvWbNGzHXq1EnkIUOGiKx/3g56igAA2EBRBABAoSgCAKCUuldHvfTSS+a4oKBAzOm9ktTUVJfHsu5bPHnypJhr1KiRyJUqVbKxStyJatWqJfLcuXNF1ve6lkRGRobIe/bsMcfPPvusy599+eWXRdYfGVeSfYuAYch93FlZWX5cyX9xpQgAgEJRBABAoSgCAKAEfU+xevXqIlv3tMyePVvM7dq1y9axXfUUH3jgAZFr1Khh69gonfTnNN5///3muEqVKmLuiSeecOx7c3NzRR4+fLjIJ06cKPJn9R7jc889J/KkSZNEpqeIkqpatao5rlOnjv8WchtcKQIAoFAUAQBQgv72afPmzUXu0KGDOe7Vq5fXvld/XNCZM2e89l0IHPprbl544QWRmzVrJrKvturo53p6enqRn/3xxx9FLm6LRmJiositW7e2uTpAqlu3rjnWX3el07culeQxb+7gShEAAIWiCACAQlEEAEAJ+p5ijx49RLb2+qyPEvKEdZtFq1atSnQsBCf9tTV6fyMsLMztY926dUvkTZs2iTxy5EiRJ0+eXOR8aGiomDty5Ijb61i4cKHITZs2FXnw4MEit2jRwu1jA+6w/g1GWlqamIuKihI5MjLSF0sycaUIAIBCUQQAQKEoAgCgBH1PMT8/32vHtu551F/7o9P7RQhelStXNsfWx7QZhr0eomHI82Ljxo1ibsCAAS5/9tVXXxW5fv365rh379621mH1999/i3z9+nWPjwXnPfTQQ/5egtdlZmaaY/3VZHpPccyYMb5YkokrRQAAFIoiAAAKRREAACXoe4q7d+927FgREREi6/vErI4fPy5yUlKSY+uAb+nPJ33ttdfMsf7apOKkpqaKfPHiRXOsv5LJrn379pljvYdNT7v0iIuL8/hnQ0JCHFyJ9zRq1Mgcd+vWzeVnc3JyvL0cgStFAAAUiiIAAErQ3z613p4yDMPIzs72+Fg9e/YU+dFHHy3ys/rjvxC89NtVb7/9tmPHst7yLKn33nvPkePor+q5E7YABLJ58+aJHBMT4/Gx9MdR6ttvrK8J27x5s5irXbu2yGXKyGsm/byxntvFvf5JZ73Nm5GRIeaaNGli61hO40oRAACFoggAgEJRBABACfqe4i+//CKyfl/cldjYWJH11wIVFBSY49dff13MHT161O3vQWB79913RbazvWH58uUinz171pE1eVP37t1FttsPgrP0f1tKsr1G35JRvnx5kcePH2+OGzZsKOYGDRoksv56sjZt2oh84MCBIuecVK5cOa8d+3a4UgQAQKEoAgCgUBQBAFBCCgsLC936YJA8PsgV/TVAO3fuFFnvR+7YscMcR0dHe21dTnLz1xn0nDwf7TwybcWKFSK/8847IltfiRNIunTpYo4XLVok5ho3buzyZ4cPHy5yQkKC29/L+Vi8+Ph4kfX90nXq1PH42N5k3QN57NgxMedkn1r/d1rvidvhzvnIlSIAAApFEQAAhaIIAIASdPsU9fvr+nMC9b6h1eDBg0XWe4hHjhwRuV+/fp4sEaWYvi82UHuILVu2FPnLL780x8Xt5R02bJjIq1evdm5h+A+9Z9uxY0eRd+3a5ZN1PPPMMyLr/fJmzZqJfOLECXM8cOBAMdepUyeR9X2MP//8sznWn/1asWJFkb/55htXy3YcV4oAACgURQAAlIC/fTp16lSRJ06cKHKFChUc+67c3FyR8/PzHTs24KSIiAiRy5aV/1eOjIwU2XrLVH+d0Lhx40ReuXKlyP/++6/H64R9hw4dEtl6e7FKlSpiTr/VfenSJZH136Ur586dEzklJUXkDz/8UOSvv/66yGOtWrXKZbaej88//7yYi4qKEvnJJ58UefHixUV+rxO4UgQAQKEoAgCgUBQBAFACrqeov84pLi5OZP1VKE7S/4x43bp15njmzJli7vDhwyLTd4HTGjRoIHKtWrXMsf64ufvuu8/lsf78809zPHnyZDGnv/4K/vXPP/+IbP07Cv3fP72/pv+svoXIDv3fOCfVr1/fHOs9RN2aNWu8to7b4UoRAACFoggAgEJRBABACbhXR2VlZYms78cqjvV/zldffSXmEhMTRdYfp9SjRw+RH3744SK/R+/L6D1Hf+FVPfbZeXWUtc9sGIaxadMmkbdt2yaytZen0x9ZqPe09f1b+iuFXNG/d/r06eb4008/dfs4JcX5iNux9hFTU1Ndfnbjxo0il+Txm7w6CgAAGyiKAAAoFEUAABS/9BSrVasmsrUfN3LkSDFXpoys2zdv3hT5u+++EzkpKckc291/FR4eLvKsWbPM8ZgxY8Sc3nd66qmnRN66daut73YKPRz77PQUi7NkyRKRf//99yI/27RpU5H1V5u5Eh8fL7Leiz9//rzLdfkK5yNux05PURcaGurx99JTBADABooiAACKXx7zpm+zGDVqlDkuKCgQc3v37hX5rbfeEtnJt1JfvXq1yO/Sb0/pb6Xu3bu3yP66fQr7nLz1pd/+t2P79u0ir127tsjPbtiwQeQrV654/L2Ar506dcoc6/+Gd+7cWeQvvvjCF0sycaUIAIBCUQQAQKEoAgCg+KWnmJubK7L10VjWx1EZhmGkpaX5ZE23k5eXZ471dZ0+fVrkCxcu+GRNcF63bt1EbtWqlTn+4IMPHPse/ZwZMWKEyBkZGSKfPHnSse8GAsnFixfN8bFjx8Sc3lPUe+3expUiAAAKRREAAIWiCACA4pee4uXLl0WOiYnxxzJKZMWKFf5eAhySnJwscnp6ujm2PjbwdhYsWCDysmXLRD569Kg5vnHjhpjLzMy0s0wAPsCVIgAACkURAACFoggAgOKXV0fBe3hVDwIJ5yMCCa+OAgDABooiAAAKRREAAIWiCACAQlEEAEChKAIAoFAUAQBQKIoAACgURQAAFIoiAACK2495AwCgtONKEQAAhaIIAIBCUQQAQKEoAgCgUBQBAFAoigAAKBRFAAAUiiIAAApFEQAA5f8AJPEynW30A3sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "rows, cols = 2, 3\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(x_train), size=[1]).item()\n",
    "    img = x_train[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we define a TinyVGG-like model for classifying MNIST data, utilizing cross-entropy loss and the SGD optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define the neural network model\n",
    "class MNISTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1,      # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MNISTModel(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(y_train[0])).to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), \n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we're integrating the previously defined PyTorch model with ART by creating an `ART classifier`. The ``PyTorchClassifier`` is initialized with several parameters including the model, clipping values for input data and a loss function. This wraps the PyTorch model, allowing it to **interact seamlessly** with various ART functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the ART classifier \n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0.0, 255.0),\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=len(y_train[0]),\n",
    "    device_type=device\n",
    ")\n",
    "\n",
    "# Step 4: Train the ART classifier\n",
    "\n",
    "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 97.82%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the ART classifier on benign (non-adversarial) test examples\n",
    "\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This high accuracy indicates that our classifier is highly effective in correctly classifying non-adversarial images. Let's generate adversarial test examples using the Fast Gradient Method and see how well the model is able to classify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Generate adversarial test examples\n",
    "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "x_test_adv = attack.generate(x=x_test)\n",
    "\n",
    "# Plot adversarial examples beside the original ones\n",
    "fig = plt.figure(figsize=(6, 4))  \n",
    "rows, cols = 2, 2\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        random_idx = torch.randint(0, len(x_test_adv), size=[1]).item()\n",
    "        \n",
    "        # Plot original image\n",
    "        ax1 = fig.add_subplot(rows, 2*cols, 2*j + 1 + i*2*cols)\n",
    "        ax1.imshow(x_test[random_idx].squeeze(), cmap=\"gray\")\n",
    "        ax1.set_title(\"Original\")\n",
    "        ax1.axis(False)\n",
    "        \n",
    "        # Plot adversarial image\n",
    "        ax2 = fig.add_subplot(rows, 2*cols, 2*j + 2 + i*2*cols)\n",
    "        ax2.imshow(x_test_adv[random_idx].squeeze(), cmap=\"gray\")\n",
    "        ax2.set_title(\"Adversarial\")\n",
    "        ax2.axis(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test examples: 11.74%\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
    "\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sharp drop in accuracy on adversarial test examples underscores the model's vulnerability to adversarial attacks. Despite performing well on benign test examples, the model struggles significantly when faced with inputs that have been subtly and maliciously perturbed, highlighting a critical area for improvement in enhancing the model's robustness against such attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Defending Against Attacks**\n",
    "\n",
    "Various defense strategies can be employed depending on the type of attack. Below, we outline some methods to counter evasion, poisoning, extraction, and inference attacks. \n",
    "\n",
    "### 1. **Defence Against Evasion Attacks:**\n",
    "   - **Adversarial Retraining:** This method involves iteratively generating adversarial examples and incorporating them into the training dataset. The model is then repeatedly trained on this augmented dataset, enhancing its robustness against specific adversarial perturbations.\n",
    "   - **Data Diversity:** Enriching the dataset with a diverse and high quality training data ensures better generalization and resilience against evasion attacks.\n",
    "\n",
    "### 2. **Defence Against Poisoning Attacks:**\n",
    "   - **Verified Sources and Developers:** Validate the credibility of both the sources providing training data, models, and code, and the developers involved, to safeguard against the integration of malicious elements.\n",
    "   - **Find Triggers:** Implement mechanisms to detect unusual patterns or triggers that indicate backdoor attacks.\n",
    "   - **Retraining:** Regularly update and retrain models with clean, verified data to mitigate the effects of poisoning.\n",
    "   - **Regularization:** Apply techniques to limit the complexity of the model, reducing its susceptibility to overfitting on poisoned data.\n",
    "\n",
    "### 3. **Defence Against Extraction Attacks:**\n",
    "   - **Output Restriction:** Limiting the scope or precision of the model’s output values can increase the effort required for attackers to replicate the model.\n",
    "   - **Rate Limiting:** Implement restrictions on the number of queries to the model to make extraction more challenging.\n",
    "\n",
    "### 4. **Defence Against Inference Attacks:**\n",
    "   - **Data Sanitization:** Use anonymization techniques to remove sensitive data, making it difficult for attackers to access private information.\n",
    "   - **Differential Privacy:** Introduce controlled noise to the data or queries, ensuring that the output does not reveal sensitive information about individual data points while maintaining overall data utility.\n",
    "\n",
    "Before deploying your ML model, conduct a risk analysis to assess the potential impact and likelihood of attacks. Simulating specific attacks is also advisable to evaluate your system's vulnerabilities and the efficacy of your defense strategies.\n",
    "\n",
    "Let's continue with our example above to perform adversarial retraining on our convolutional classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Generate adversarial training examples\n",
    "x_train_adversarial = attack.generate(x=x_train[:2000])\n",
    "y_train_adversarial = y_train[:2000]\n",
    "\n",
    "x_train_combined = np.concatenate((x_train, x_train_adversarial))\n",
    "y_train_combined = np.concatenate((y_train, y_train_adversarial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Retrain the ART classifier on combined (original and adversarial) training examples\n",
    "\n",
    "classifier.fit(x_train_combined, y_train_combined, batch_size=64, nb_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test examples: 88.23%\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate the ART classifier on adversarial test examples\n",
    "\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the increased accuracy indicates that the model has become more robust following adversarial retraining. \n",
    "\n",
    "You can repeat steps 3-5 until the model is sufficiently adversarially robust. It is worth mentioning that adversarial retraining can lead to overfitting. Therefore, there are a number of things that can be done to reduce the risk of overfitting when performing adversarial retraining:\n",
    "\n",
    "* Use a variety of adversarial attacks to generate adversarial examples. This will help to ensure that the model is robust to a wide range of adversarial attacks, rather than just a specific type of attack.\n",
    "* Use a large and diverse training dataset. This will help to ensure that the model is able to generalize to new data, even if the adversarial examples used to train the model are not perfectly representative of all possible adversarial attacks.\n",
    "* Use early stopping: monitor the model's performance on a validation set and stop training when the performance starts to degrade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Further Reading:\n",
    "\n",
    "In this article, we’ve explored AI security, focusing on the challenges of different types of attacks and how to defend against them. We used the Adversarial Robustness Toolbox (ART) to show real-world examples of these challenges and solutions.\n",
    "\n",
    "As AI becomes more ingrained in our daily lives and business operations, and especially with the advent of powerful tools like LLMs, securing these systems against malicious attacks is paramount.\n",
    "\n",
    "For those looking to dig deeper, there are many specialized resources available that offer more comprehensive information on AI security:\n",
    "* [Artificial Intelligence (AI) Governance and Cyber-Security: A beginner’s handbook on securing and governing AI systems](https://www.amazon.de/-/en/Taimur-Ijlal/dp/B09YHK8L2T).\n",
    "* [AI security concerns in a nutshell - Practical AI-Security guide](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/Practical_Al-Security_Guide_2023.html).\n",
    "* [AI-systems: develop them securely](https://english.aivd.nl/publications/publications/2023/02/15/ai-systems-develop-them-securely).\n",
    "* [Securing Machine Learning Algorithms](https://www.enisa.europa.eu/publications/securing-machine-learning-algorithms).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
